{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1304a6a0-9dc2-4ff6-8cf5-5a6b4c9fbb6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ea0b7d2-0e1a-4f5e-ba3f-057b3b1dc6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import csv\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "\n",
    "# ——— Setup logging ———\n",
    "logging.basicConfig(\n",
    "    filename=\"logs/ingestion_db.log\",\n",
    "    level=logging.DEBUG,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "# ——— Config ———\n",
    "DATA_DIR = \"data\"\n",
    "DB_PATH  = \"inventory.db\"\n",
    "BATCH_SZ = 10_000    # commit every 10k rows\n",
    "\n",
    "def ingest_csv(file_path, conn):\n",
    "    \"\"\"\n",
    "    Stream a CSV into SQLite with pure sqlite3:\n",
    "      - creates (or replaces) a table named after the file (minus “.csv”)\n",
    "      - reads rows in batches of BATCH_SZ\n",
    "      - uses executemany() per batch (never > 1 row of placeholders)\n",
    "    \"\"\"\n",
    "    table_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    # open CSV & read header\n",
    "    with open(file_path, newline=\"\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.reader(f)\n",
    "        headers = next(reader)\n",
    "        cols_def = \", \".join(f'\"{h}\" TEXT' for h in headers)\n",
    "\n",
    "        # (re)create table\n",
    "        cur.execute(f'DROP TABLE IF EXISTS \"{table_name}\"')\n",
    "        cur.execute(f'CREATE TABLE \"{table_name}\" ({cols_def})')\n",
    "\n",
    "        # prepare INSERT\n",
    "        placeholder = \", \".join(\"?\" for _ in headers)\n",
    "        sql_insert  = f'INSERT INTO \"{table_name}\" VALUES ({placeholder})'\n",
    "\n",
    "        # stream rows in batches\n",
    "        batch = []\n",
    "        for row in reader:\n",
    "            batch.append(tuple(row))\n",
    "            if len(batch) >= BATCH_SZ:\n",
    "                cur.executemany(sql_insert, batch)\n",
    "                conn.commit()\n",
    "                batch.clear()\n",
    "\n",
    "        # final partial batch\n",
    "        if batch:\n",
    "            cur.executemany(sql_insert, batch)\n",
    "            conn.commit()\n",
    "\n",
    "    logging.info(f\"Finished ingesting {table_name} ({file_path})\")\n",
    "\n",
    "def load_all_csvs():\n",
    "    start = time.time()\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    try:\n",
    "        for fname in os.listdir(DATA_DIR):\n",
    "            if not fname.lower().endswith(\".csv\"):\n",
    "                continue\n",
    "            path = os.path.join(DATA_DIR, fname)\n",
    "            logging.info(f\"Starting {fname}\")\n",
    "            ingest_csv(path, conn)\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "    mins = (time.time() - start) / 60\n",
    "    logging.info(f\"All files ingested in {mins:.2f} minutes\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    load_all_csvs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24de86e-afc8-4dcd-9b0d-cb949f0b142f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
